# 决策树算法详解

## 信息熵
信息熵衡量数据集的不确定性或混乱程度：
$$
H(D) = -\sum_{i=1}^{n} p_i \log_2 (p_i)
$$

其中：
- $D$：数据集
- $n$：类别的数量
- $p_i$：类别 $i$ 在数据集 $D$ 中的比例

**熵的性质**：
- 当数据集完全纯净时（只有一个类别），熵为0
- 当各类别均匀分布时，熵达到最大值
- 对于二分类问题，最大熵为1

## 信息增益  
信息增益衡量使用特征A进行分裂后，数据集不确定性的减少程度：
$$
Gain(D, A) = H(D) - \sum_{v=1}^{V} \frac{|D_v|}{|D|} H(D_v)
$$

其中：
- $A$：选择的特征
- $V$：特征 $A$ 的取值个数
- $D_v$：特征 $A$ 取值为 $v$ 的子集
- $|D_v|$：子集 $D_v$ 的样本数
- $|D|$：总样本数

**ID3算法**使用信息增益作为特征选择标准。

## 信息增益率
为了解决信息增益偏向取值多的特征的问题，**C4.5算法**使用信息增益率：
$$
GainRatio(D,A) = \frac{Gain(D,A)}{SplitInfo(D,A)}
$$

分裂信息（固有值）衡量特征取值的分布均匀程度：
$$
SplitInfo(D,A) = -\sum_{v=1}^V \frac{|D_v|}{|D|} \log_2\left( \frac{|D_v|}{|D|} \right)
$$

## 基尼系数
基尼系数衡量数据集的不纯度：
$$
Gini(D) = 1 - \sum_{i=1}^{n} p_i^2
$$

基尼增益衡量使用特征A分裂后的不纯度减少程度：
$$
\Delta Gini = Gini(D) - \sum_{v=1}^{V} \frac{|D_v|}{|D|} Gini(D_v)
$$

**CART算法**使用基尼系数作为分裂标准。


**示例数据集**
假设我们有一个简单的天气数据集用于预测是否适合打网球：

| 天气 | 温度 | 湿度 | 风速 | 是否打网球 |
|------|------|------|------|------------|
| 晴朗 | 高   | 高   | 弱   | 否         |
| 晴朗 | 高   | 高   | 强   | 否         |
| 多云 | 高   | 高   | 弱   | 是         |
| 下雨 | 中   | 高   | 弱   | 是         |
| 下雨 | 低   | 正常 | 弱   | 是         |
| 下雨 | 低   | 正常 | 强   | 否         |
| 多云 | 低   | 正常 | 强   | 是         |
| 晴朗 | 中   | 高   | 弱   | 否         |
| 晴朗 | 低   | 正常 | 弱   | 是         |
| 下雨 | 中   | 正常 | 弱   | 是         |
| 晴朗 | 中   | 正常 | 强   | 是         |
| 多云 | 中   | 高   | 强   | 是         |
| 多云 | 高   | 正常 | 弱   | 是         |
| 下雨 | 中   | 高   | 强   | 否         |

**计算根节点的熵**
首先计算整个数据集的熵：
- 总样本数：14
- "是"类别样本数：9
- "否"类别样本数：5

$$
H(D) = -\left( \frac{9}{14} \log_2 \frac{9}{14} + \frac{5}{14} \log_2 \frac{5}{14} \right)
$$

计算各项：
- $\frac{9}{14} \approx 0.6429$, $\log_2 0.6429 \approx -0.6374$
- $\frac{5}{14} \approx 0.3571$, $\log_2 0.3571 \approx -1.4854$

$$
H(D) = -(0.6429 \times -0.6374 + 0.3571 \times -1.4854) \approx 0.940
$$

**计算天气特征的信息增益**

天气特征的取值分布：
- **晴朗**：5个样本（2个"是"，3个"否"）
- **多云**：4个样本（4个"是"，0个"否"）  
- **下雨**：5个样本（3个"是"，2个"否"）

计算各子集的熵：  
**晴朗子集的熵**：
$$
H(D_{晴朗}) = -\left( \frac{2}{5} \log_2 \frac{2}{5} + \frac{3}{5} \log_2 \frac{3}{5} \right) \approx 0.971
$$

**多云子集的熵**：
$$
H(D_{多云}) = -\left( \frac{4}{4} \log_2 \frac{4}{4} + \frac{0}{4} \log_2 \frac{0}{4} \right) = 0
$$

**下雨子集的熵**：
$$
H(D_{下雨}) = -\left( \frac{3}{5} \log_2 \frac{3}{5} + \frac{2}{5} \log_2 \frac{2}{5} \right) \approx 0.971
$$

计算加权平均熵：
$$
H_{天气}(D) = \frac{5}{14} \times 0.971 + \frac{4}{14} \times 0 + \frac{5}{14} \times 0.971 \approx 0.694
$$

计算信息增益：
$$
Gain(D, 天气) = H(D) - H_{天气}(D) = 0.940 - 0.694 = 0.246
$$

计算温度特征的信息增益

温度特征的取值分布：
- **高**：4个样本（2个"是"，2个"否"）
- **中**：6个样本（4个"是"，2个"否"）
- **低**：4个样本（3个"是"，1个"否"）

计算各子集的熵：  
**高温度子集的熵**：
$$
H(D_{高}) = -\left( \frac{2}{4} \log_2 \frac{2}{4} + \frac{2}{4} \log_2 \frac{2}{4} \right) = 1.0
$$

**中温度子集的熵**：
$$
H(D_{中}) = -\left( \frac{4}{6} \log_2 \frac{4}{6} + \frac{2}{6} \log_2 \frac{2}{6} \right) \approx 0.918
$$

**低温度子集的熵**：
$$
H(D_{低}) = -\left( \frac{3}{4} \log_2 \frac{3}{4} + \frac{1}{4} \log_2 \frac{1}{4} \right) \approx 0.811
$$

计算加权平均熵：
$$
H_{温度}(D) = \frac{4}{14} \times 1.0 + \frac{6}{14} \times 0.918 + \frac{4}{14} \times 0.811 \approx 0.911
$$

计算信息增益：
$$
Gain(D, 温度) = 0.940 - 0.911 = 0.029
$$

计算基尼系数

根节点的基尼系数：
$$
Gini(D) = 1 - \left( \left(\frac{9}{14}\right)^2 + \left(\frac{5}{14}\right)^2 \right) = 1 - (0.413 + 0.128) = 0.459
$$

天气特征的基尼增益：  
**晴朗子集的基尼系数**：
$$
Gini(D_{晴朗}) = 1 - \left( \left(\frac{2}{5}\right)^2 + \left(\frac{3}{5}\right)^2 \right) = 1 - (0.16 + 0.36) = 0.48
$$

**多云子集的基尼系数**：
$$
Gini(D_{多云}) = 1 - \left( \left(\frac{4}{4}\right)^2 + \left(\frac{0}{4}\right)^2 \right) = 0
$$

**下雨子集的基尼系数**：
$$
Gini(D_{下雨}) = 1 - \left( \left(\frac{3}{5}\right)^2 + \left(\frac{2}{5}\right)^2 \right) = 1 - (0.36 + 0.16) = 0.48
$$

计算基尼增益：
$$
\Delta Gini_{天气} = 0.459 - \left( \frac{5}{14} \times 0.48 + \frac{4}{14} \times 0 + \frac{5}{14} \times 0.48 \right) = 0.459 - 0.343 = 0.116
$$

特征选择结果比较

| 特征 | 信息增益 | 基尼增益 |
|------|----------|----------|
| 天气 | 0.246    | 0.116    |
| 温度 | 0.029    | 0.013    |

**结论**：天气特征的信息增益和基尼增益都最大，因此选择天气作为根节点的分裂特征。



<div style="height: 2px; background: linear-gradient(to right, #FF85C0, #2196F3, #4CAF50); border-radius: 1px; margin: 20px 0;"></div>  

[返回](./supervised_learning.md#决策树)