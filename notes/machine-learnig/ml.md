# 机器学习


**有监督学习（Supervised Learning）**

监督学习（Supervised Learning）是机器学习的核心分支之一，其核心特征是**使用带标签的训练数据**指导模型学习。简单来说，监督学习就像“有老师指导的学习”——训练数据不仅包含输入特征，还附带对应的“标准答案”（标签），模型通过学习特征与标签的映射关系，最终具备对新数据预测标签的能力。

监督学习的核心目标是构建一个精准的映射函数  $f: X \rightarrow Y$ ，其中  $X$  是特征空间（输入数据）， $Y$  是标签空间（输出结果）。例如：

- 输入  $X$  = 房屋面积、地段、户型 → 输出  $Y$  = 房屋价格（回归任务）；

- 输入  $X$  = 邮件内容、发件人、关键词 → 输出  $Y$  = 垃圾邮件/正常邮件（分类任务）。

**无监督学习（Unsupervised Learning）**

无监督学习是“无老师自主探索的学习”，核心特征是使用**无标签的训练数据**（仅输入特征，无标准答案）。模型无需外部指导，通过挖掘数据内在的结构、规律或分布，实现聚类、降维、异常检测等目标。

## 有监督学习

**带标签的数据集**

数据集是监督学习的基础，必须满足“特征+标签”的成对结构，按用途可分为三类：

- **训练集（Training Set）**：占比60%-80%，用于模型学习特征与标签的关系，是模型的“学习素材”；

- **验证集（Validation Set）**：占比10%-20%，用于调整模型参数（如正则化强度）、选择模型结构，避免过拟合；

- **测试集（Test Set）**：占比10%-20%，完全独立于训练过程，用于评估模型的泛化能力（对新数据的预测效果）。

**学习算法**

算法是监督学习的“学习方法”，负责从数据中提取规律，常见核心算法包括：

- 回归算法：线性回归、逻辑回归（二分类）、多项式回归；

- 分类算法：决策树、随机森林、支持向量机（SVM）、K近邻（KNN）、神经网络；

- 集成算法：梯度提升树（XGBoost、LightGBM）、AdaBoost。

**损失函数与优化器**

- **损失函数（Loss Function）**：衡量模型预测值与真实标签的差异，是模型优化的“导航仪”。例如：

    - 回归任务：均方误差（MSE）、平均绝对误差（MAE）；

    - 分类任务：交叉熵损失（Cross-Entropy）、铰链损失（Hinge Loss，适用于SVM）。

- **优化器（Optimizer）**：通过调整模型参数，最小化损失函数，常见包括梯度下降（GD）、随机梯度下降（SGD）、Adam、RMSProp等。


### 工作流程

1. **问题定义**：明确任务类型（回归/分类）、输入特征范围、目标标签定义；

2. **数据收集与预处理**：

    - 数据收集：获取带标签的高质量数据（避免标签错误、特征缺失）；

    - 数据清洗：处理缺失值（填充/删除）、异常值（3σ原则/箱型图检测）、重复值；

    - 特征工程：特征选择（保留有效特征）、特征转换（归一化/标准化、类别特征编码）；

3. **数据集划分**：按比例拆分训练集、验证集、测试集（注意避免数据泄露，如先划分再预处理）；

4. **模型选择与训练**：

    - 选择适配任务的算法（如回归选线性回归，多分类选随机森林）；

    - 用训练集训练模型，通过验证集调整参数（如决策树剪枝、SVM核函数选择）；

5. **模型评估**：用测试集评估模型性能，核心指标见下文；

6. **模型优化与部署**：

    - 优化方向：特征工程优化、参数调优（网格搜索/随机搜索）、算法替换；

    - 部署：将优化后的模型封装为服务，应用于实际业务场景（如API接口、嵌入式设备）。

### 评估指标

**回归任务评估指标**

- **均方误差（MSE）**： $\text{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$ ，衡量预测值与真实值的平方误差均值，值越小越好；

- **平均绝对误差（MAE）**： $\text{MAE} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|$ ，衡量绝对误差均值，对异常值更稳健；

- **均方根误差（RMSE）**： $\text{RMSE} = \sqrt{\text{MSE}}$ ，与MSE类似，但计算开销更小，适用于数据量较大、特征数量多的场景。

- **决定系数（** $R^2$  **）**：取值范围[0,1]，表示模型解释数据变异的能力， $R^2$  越接近1，模型拟合效果越好。

**分类任务评估指标**

- **准确率（Accuracy）**： $\text{Accuracy} = \frac{\text{正确预测数}}{\text{总样本数}}$ ，适用于类别均衡的场景；

- **精确率（Precision）**： $\text{Precision} = \frac{\text{真阳性数}}{\text{预测阳性数}}$ ，衡量预测为阳性的样本中真实阳性的比例（适用于“假阳性代价高”的场景，如垃圾邮件识别）；

- **召回率（Recall）**： $\text{Recall} = \frac{\text{真阳性数}}{\text{真实阳性数}}$ ，衡量真实阳性样本中被正确预测的比例（适用于“假阴性代价高”的场景，如疾病诊断）；

- **F1分数**： $\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ ，综合精确率和召回率，适用于类别不平衡场景；

- **AUC-ROC**：衡量模型区分正负类的能力，取值范围[0.5,1]，越接近1分类效果越好。
  1. ROC 曲线：以假阳性率（FPR，假阳性数 / 负样本总数）为横轴、真阳性率（TPR，真阳性数 / 正样本总数）为纵轴，通过遍历所有预测概率阈值计算对应 FPR 和 TPR 绘制而成；理想模型的 ROC 曲线紧贴左上角，即 FPR 趋近于 0 且 TPR 趋近于 1。  
  2. AUC：指 ROC 曲线下的面积，取值范围为 0~1；AUC=1 代表模型完美区分正负样本，AUC=0.5 则模型无区分能力，AUC 越接近 1 模型区分能力越强。
  3. 核心特点：对类别不平衡鲁棒，且聚焦模型对正负样本的排序能力，不依赖具体分类阈值。

## 无监督学习

**核心要素**

- **无标签数据集**：无需划分验证集，仅需训练集（模型探索）和测试集（效果验证）；

- **核心算法**：聚类（K-Means、层次聚类、DBSCAN）、降维（PCA、t-SNE、LDA）、异常检测（孤立森林、One-Class SVM）；

- **评价指标**：无统一“标准答案”，依赖数据内在结构评估。

#### 核心任务

**聚类任务**

- 目标：将相似样本归为一类，不依赖先验标签；

- 典型场景：客户价值分群、用户行为聚类、商品分类；

- 代表算法：K-Means（指定簇数，高效简单）、DBSCAN（无需指定簇数，抗异常值）。

**降维任务**

- 目标：在保留数据核心信息的前提下，减少特征维度（去冗余、提效率）；

- 典型场景：高维数据可视化、模型训练提速、噪声过滤；

- 代表算法：PCA（线性降维，保留方差最大方向）、t-SNE（非线性降维，适合可视化）。

**异常检测任务**

- 目标：识别数据中偏离正常分布的“异常样本”；

- 典型场景：欺诈交易检测、设备故障预警、数据录入错误识别；

- 代表算法：孤立森林、One-Class SVM、DBSCAN（基于密度的异常检测）。

**关键评估指标**

- 聚类任务：轮廓系数（越接近1聚类效果越好）、惯性值（簇内样本距离和，越小越好）；

- 降维任务：重构误差（降维后恢复原始数据的误差）、解释方差比（保留的信息比例）；

- 异常检测：精确率、召回率（需少量标注异常样本辅助验证）。
